{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "import subprocess\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from config import PGEND_POINT\n",
    "from config import PGDATABASE_NAME\n",
    "from config import PGUSER_NAME\n",
    "from config import PGPASSWORD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS RDS Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect():\n",
    "    \n",
    "    # Set up a connection to the postgres server.\n",
    "    conn_string = \"host=\"+ PGEND_POINT +\" port=\"+ \"5432\" +\" dbname=\"+ PGDATABASE_NAME +\" user=\" + PGUSER_NAME \\\n",
    "                  +\" password=\"+ PGPASSWORD\n",
    "    \n",
    "    conn = psycopg2.connect(conn_string)\n",
    "    print(\"Connected!\")\n",
    "\n",
    "    # Create a cursor object\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    return conn, cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected!\n"
     ]
    }
   ],
   "source": [
    "conn, cursor = connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create earthquakes table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the earthquakes table\n",
    "query_earthquakes = sql.SQL(\"\"\"CREATE TABLE earthquakes (\n",
    "  latitude DECIMAL,\n",
    "  longitude DECIMAL,\n",
    "  magnitude DECIMAL,\n",
    "  event_date DATE\n",
    ");\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction committed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create a cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    # Execute your SQL statements here\n",
    "    cur.execute(query_earthquakes)\n",
    "\n",
    "    # If everything is successful, commit the transaction\n",
    "    conn.commit()\n",
    "    print(\"Transaction committed successfully!\")\n",
    "except psycopg2.Error as e:\n",
    "    # If an error occurs, rollback the transaction\n",
    "    conn.rollback()\n",
    "    print(\"Transaction rolled back due to error:\", e)\n",
    "finally:\n",
    "    # Close the cursor and connection\n",
    "    cur.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create injectionVolumes table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the injectionVolumes table\n",
    "query_injectionVolumes = sql.SQL(\"\"\"CREATE TABLE injection_volumes (\n",
    "  api_number INT,\n",
    "  surface_longitude DECIMAL,\n",
    "  surface_latitude DECIMAL,\n",
    "  injection_date DATE,\n",
    "  injection_end_date DATE,\n",
    "  volume_injected_bbls DECIMAL\n",
    ");\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction committed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create a cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    # Execute your SQL statements here\n",
    "    cur.execute(query_injectionVolumes)\n",
    "\n",
    "    # If everything is successful, commit the transaction\n",
    "    conn.commit()\n",
    "    print(\"Transaction committed successfully!\")\n",
    "except psycopg2.Error as e:\n",
    "    # If an error occurs, rollback the transaction\n",
    "    conn.rollback()\n",
    "    print(\"Transaction rolled back due to error:\", e)\n",
    "finally:\n",
    "    # Close the cursor and connection\n",
    "    cur.close()\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pressureData table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the pressureData table\n",
    "query_pressureData = sql.SQL(\"\"\"CREATE TABLE pressure_data (\n",
    "  time DATE,\n",
    "  pressure DECIMAL,\n",
    "  layer VARCHAR(10),\n",
    "  longitude DECIMAL,\n",
    "  latitude DECIMAL\n",
    ");\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction committed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create a cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    # Execute your SQL statements here\n",
    "    cur.execute(query_pressureData)\n",
    "\n",
    "    # If everything is successful, commit the transaction\n",
    "    conn.commit()\n",
    "    print(\"Transaction committed successfully!\")\n",
    "except psycopg2.Error as e:\n",
    "    # If an error occurs, rollback the transaction\n",
    "    conn.rollback()\n",
    "    print(\"Transaction rolled back due to error:\", e)\n",
    "finally:\n",
    "    # Close the cursor and connection\n",
    "    cur.close()\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the query_pressureData_13 table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the query_pressureData_13 table\n",
    "query_pressureData_13 = sql.SQL(\"\"\"CREATE TABLE pressure_data_13 (\n",
    "  time DATE,\n",
    "  pressure DECIMAL,\n",
    "  layer VARCHAR(10),\n",
    "  longitude DECIMAL,\n",
    "  latitude DECIMAL,\n",
    "  delta DECIMAL\n",
    ");\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction committed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create a cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    # Execute your SQL statements here\n",
    "    cur.execute(query_pressureData_13)\n",
    "\n",
    "    # If everything is successful, commit the transaction\n",
    "    conn.commit()\n",
    "    print(\"Transaction committed successfully!\")\n",
    "except psycopg2.Error as e:\n",
    "    # If an error occurs, rollback the transaction\n",
    "    conn.rollback()\n",
    "    print(\"Transaction rolled back due to error:\", e)\n",
    "finally:\n",
    "    # Close the cursor and connection\n",
    "    cur.close()\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the query_pressureData_9 table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the query_pressureData_9 table\n",
    "query_pressureData_9 = sql.SQL(\"\"\"CREATE TABLE pressure_data_9 (\n",
    "  time DATE,\n",
    "  pressure DECIMAL,\n",
    "  layer VARCHAR(10),\n",
    "  longitude DECIMAL,\n",
    "  latitude DECIMAL,\n",
    "  delta DECIMAL\n",
    ");\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction committed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create a cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    # Execute your SQL statements here\n",
    "    cur.execute(query_pressureData_9)\n",
    "\n",
    "    # If everything is successful, commit the transaction\n",
    "    conn.commit()\n",
    "    print(\"Transaction committed successfully!\")\n",
    "except psycopg2.Error as e:\n",
    "    # If an error occurs, rollback the transaction\n",
    "    conn.rollback()\n",
    "    print(\"Transaction rolled back due to error:\", e)\n",
    "finally:\n",
    "    # Close the cursor and connection\n",
    "    cur.close()\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the query_pressureData_11 table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the query_pressureData_11 table\n",
    "query_pressureData_11 = sql.SQL(\"\"\"CREATE TABLE pressure_data_11 (\n",
    "  time DATE,\n",
    "  pressure DECIMAL,\n",
    "  layer VARCHAR(10),\n",
    "  longitude DECIMAL,\n",
    "  latitude DECIMAL,\n",
    "  delta DECIMAL\n",
    ");\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction committed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create a cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    # Execute your SQL statements here\n",
    "    cur.execute(query_pressureData_11)\n",
    "\n",
    "    # If everything is successful, commit the transaction\n",
    "    conn.commit()\n",
    "    print(\"Transaction committed successfully!\")\n",
    "except psycopg2.Error as e:\n",
    "    # If an error occurs, rollback the transaction\n",
    "    conn.rollback()\n",
    "    print(\"Transaction rolled back due to error:\", e)\n",
    "finally:\n",
    "    # Close the cursor and connection\n",
    "    cur.close()\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the query_pressureData_19 table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the pressureData table\n",
    "query_pressureData_19 = sql.SQL(\"\"\"CREATE TABLE pressure_data_19 (\n",
    "  time DATE,\n",
    "  pressure DECIMAL,\n",
    "  layer VARCHAR(10),\n",
    "  longitude DECIMAL,\n",
    "  latitude DECIMAL,\n",
    "  delta DECIMAL\n",
    ");\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction committed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create a cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    # Execute your SQL statements here\n",
    "    cur.execute(query_pressureData_19)\n",
    "\n",
    "    # If everything is successful, commit the transaction\n",
    "    conn.commit()\n",
    "    print(\"Transaction committed successfully!\")\n",
    "except psycopg2.Error as e:\n",
    "    # If an error occurs, rollback the transaction\n",
    "    conn.rollback()\n",
    "    print(\"Transaction rolled back due to error:\", e)\n",
    "finally:\n",
    "    # Close the cursor and connection\n",
    "    cur.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the query_pressureData_revised table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the pressureData table\n",
    "query_pressureData_revised = sql.SQL(\"\"\"CREATE TABLE pressure_data_revised (\n",
    "  time DATE,\n",
    "  pressure DECIMAL,\n",
    "  layer VARCHAR(10),\n",
    "  longitude DECIMAL,\n",
    "  latitude DECIMAL,\n",
    "  delta DECIMAL\n",
    ");\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction committed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create a cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "try:\n",
    "    # Execute your SQL statements here\n",
    "    cur.execute(query_pressureData_revised)\n",
    "\n",
    "    # If everything is successful, commit the transaction\n",
    "    conn.commit()\n",
    "    print(\"Transaction committed successfully!\")\n",
    "except psycopg2.Error as e:\n",
    "    # If an error occurs, rollback the transaction\n",
    "    conn.rollback()\n",
    "    print(\"Transaction rolled back due to error:\", e)\n",
    "finally:\n",
    "    # Close the cursor and connection\n",
    "    cur.close()\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions and variables required to load data into the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect():\n",
    "    # Set up a connection to the postgres server.\n",
    "    conn_string = f\"postgresql+psycopg2://{PGUSER_NAME}:{PGPASSWORD}@{PGEND_POINT}:5432/{PGDATABASE_NAME}\"\n",
    "    engine = create_engine(conn_string)\n",
    "    print(\"Connected to the database!\")\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to push DataFrames into PGadmin tables that were created\n",
    "def load_data_to_table(dataframe, table_name, engine):\n",
    "    dataframe.to_sql(name=table_name, con=engine, if_exists='append', index=False)\n",
    "    print(f\"Data loaded into {table_name} successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the database!\n"
     ]
    }
   ],
   "source": [
    "# Connect to the database\n",
    "engine = connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames from the CSV files\n",
    "injection_volumes_df = pd.read_csv('../../data/data_seis/injectionVolumes.csv')\n",
    "pressure_data_df = pd.read_csv('../../data/data_seis/Updated_Pressure_Data_with_LatLon.csv')\n",
    "earthquakes_df = pd.read_csv('../../data/data_seis/earthquakes.csv')\n",
    "pressure_data_13_df = pd.read_csv('../../data/data_seis/delta_pressure_layer13.csv')\n",
    "pressure_data_9_df = pd.read_csv('../../data/data_seis/delta_pressure_layer9.csv')\n",
    "pressure_data_11_df = pd.read_csv('../../data/data_seis/delta_pressure_layer11.csv')\n",
    "pressure_data_19_df = pd.read_csv('../../data/data_seis/delta_pressure_layer19.csv')\n",
    "pressure_data_revised_df = pd.read_csv('../../data/data_seis/delta_pressure_all_layers.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load earthquakes data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename earthquakes columns to match the table\n",
    "earthquakes_df.rename(columns={'Latitude': 'latitude', 'Longitude': 'longitude', 'Magnitude': 'magnitude', 'Event_Date': 'event_date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded into earthquakes successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the earthquakes data\n",
    "load_data_to_table(earthquakes_df, 'earthquakes', engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load injectionVolumes data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename injectionVolumes columns to match the table\n",
    "injection_volumes_df.rename(columns={'API Number': 'api_number', 'Surface Longitude': 'surface_longitude', 'Surface Latitude': 'surface_latitude', 'Injection Date': 'injection_date', 'Injection End Date': 'injection_end_date',\n",
    "                                     'Volume Injected: BBLs': 'volume_injected_bbls'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded into injection_volumes successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the injectionVolumes data\n",
    "load_data_to_table(injection_volumes_df, 'injection_volumes', engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pressure data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded into pressure_data successfully!\n"
     ]
    }
   ],
   "source": [
    "# Rename pressureData columns to match the table\n",
    "pressure_data_df.rename(columns={'Time': 'time', 'Pressure': 'pressure', 'Layer': 'layer', 'Longitude': 'longitude', 'Latitude': 'latitude'}, inplace=True)\n",
    "\n",
    "# Load the pressure data\n",
    "load_data_to_table(pressure_data_df, 'pressure_data', engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pressure data for layer 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded into pressure_data_13 successfully!\n"
     ]
    }
   ],
   "source": [
    "# Rename pressure_data_13 columns to match the table\n",
    "pressure_data_13_df.rename(columns={'Time': 'time', 'Pressure': 'pressure', 'Layer': 'layer', 'Longitude': 'longitude', 'Latitude': 'latitude', 'Delta_Pressure': 'delta'}, inplace=True)\n",
    "\n",
    "# Load the pressure data\n",
    "load_data_to_table(pressure_data_13_df, 'pressure_data_13', engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pressure data for layer 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded into pressure_data_9 successfully!\n"
     ]
    }
   ],
   "source": [
    "# Rename pressure_data_9 columns to match the table\n",
    "pressure_data_9_df.rename(columns={'Time': 'time', 'Pressure': 'pressure', 'Layer': 'layer', 'Longitude': 'longitude', 'Latitude': 'latitude', 'Delta_Pressure': 'delta'}, inplace=True)\n",
    "\n",
    "# Load the pressure data\n",
    "load_data_to_table(pressure_data_9_df, 'pressure_data_9', engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pressure data for layer 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded into pressure_data_11 successfully!\n"
     ]
    }
   ],
   "source": [
    "# Rename pressure_data_11 columns to match the table\n",
    "pressure_data_11_df.rename(columns={'Time': 'time', 'Pressure': 'pressure', 'Layer': 'layer', 'Longitude': 'longitude', 'Latitude': 'latitude', 'Delta_Pressure': 'delta'}, inplace=True)\n",
    "\n",
    "# Load the pressure data\n",
    "load_data_to_table(pressure_data_11_df, 'pressure_data_11', engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pressure data for layer 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded into pressure_data_19 successfully!\n"
     ]
    }
   ],
   "source": [
    "# Rename pressure_data_19 columns to match the table\n",
    "pressure_data_19_df.rename(columns={'Time': 'time', 'Pressure': 'pressure', 'Layer': 'layer', 'Longitude': 'longitude', 'Latitude': 'latitude', 'Delta_Pressure': 'delta'}, inplace=True)\n",
    "\n",
    "# Load the pressure data\n",
    "load_data_to_table(pressure_data_19_df, 'pressure_data_19', engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pressure data for all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded into pressure_data_revised successfully!\n"
     ]
    }
   ],
   "source": [
    "# Rename pressure_data_revised columns to match the table\n",
    "pressure_data_revised_df.rename(columns={'Time': 'time', 'Pressure': 'pressure', 'Layer': 'layer', 'Longitude': 'longitude', 'Latitude': 'latitude', 'Delta': 'delta'}, inplace=True)\n",
    "\n",
    "# Load the pressure data\n",
    "load_data_to_table(pressure_data_revised_df, 'pressure_data_revised', engine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
